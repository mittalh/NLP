{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a midnight dreary, while I pondered, weak and weary,\n",
      "Over many a quaint and curious volume of forgotten lore –\n",
      "While I nodded, nearly napping, suddenly there came a tapping,\n",
      "As of some one gently rapping, rapping at my chamber door –\n",
      "\"'Tis some visitor,\" I muttered, \"tapping at my chamber door –\n",
      "Only this and nothing more.\"\n",
      "\n",
      "Ah, distinctly I remember it was in the bleak December;\n",
      "And each separate dying ember wrought its ghost upon the floor.\n",
      "Eagerly I wished the morrow; – vainly I had sought to borrow\n",
      "From my books surcease of sorrow – sorrow for the lost Lenore –\n",
      "For the rare and radiant maiden whom the angels name Lenore –\n",
      "Nameless here for evermore.\n",
      "\n",
      "And the silken, sad, uncertain rustling of each purple curtain\n",
      "Thrilled me – filled me with fantastic terrors never felt before;\n",
      "So that now, to still the beating of my heart, I stood repeating,\n",
      "\"'Tis some visitor entreating entrance at my chamber door –\n",
      "Some late visitor entreating entrance at my chamber door; –\n",
      "This it is and nothing more.\"\n",
      "\n",
      "Presently my soul grew stronger; hesitating then no longer,\n",
      "\"Sir,\" said I, \"or Madam, truly your forgiveness I implore;\n",
      "But the fact is I was napping, and so gently you came rapping,\n",
      "And so faintly you came tapping, tapping at my chamber door,\n",
      "That I scarce was sure I heard you\" – here I opened wide the door; –\n",
      "Darkness there and nothing more.\n",
      "\n",
      "Deep into that darkness peering, long I stood there wondering, fearing,\n",
      "Doubting, dreaming dreams no mortal ever dared to dream before;\n",
      "But the silence was unbroken, and the stillness gave no token,\n",
      "And the only word there spoken was the whispered word, \"Lenore?\"\n",
      "This I whispered, and an echo murmured back the word, \"Lenore!\" –\n",
      "Merely this and nothing more.\n",
      "\n",
      "Back into the chamber turning, all my soul within me burning,\n",
      "Soon again I heard a tapping somewhat louder than before.\n",
      "\"Surely,\" said I, \"surely that is something at my window lattice;\n",
      "Let me see, then, what thereat is, and this mystery explore –\n",
      "Let my heart be still a moment and this mystery explore; –\n",
      "'Tis the wind and nothing more!\"\n",
      "\n",
      "Open here I flung the shutter, when, with many a flirt and flutter,\n",
      "In there stepped a stately Raven of the saintly days of yore;\n",
      "Not the least obeisance made he; not a minute stopped or stayed he;\n",
      "But, with mien of lord or lady, perched above my chamber door –\n",
      "Perched upon a bust of Pallas just above my chamber door –\n",
      "Perched, and sat, and nothing more.\n",
      "\n",
      "Then this ebony bird beguiling my sad fancy into smiling,\n",
      "By the grave and stern decorum of the countenance it wore,\n",
      "\"Though thy crest be shorn and shaven, thou,\" I said, \"art sure no craven,\n",
      "Ghastly grim and ancient Raven wandering from the Nightly shore –\n",
      "Tell me what thy lordly name is on the Night's Plutonian shore!\"\n",
      "Quoth the Raven \"Nevermore.\"\n",
      "\n",
      "Much I marvelled this ungainly fowl to hear discourse so plainly,\n",
      "Though its answer little meaning – little relevancy bore;\n",
      "For we cannot help agreeing that no living human being\n",
      "Ever yet was blest with seeing bird above his chamber door –\n",
      "Bird or beast upon the sculptured bust above his chamber door,\n",
      "With such name as \"Nevermore.\"\n",
      "\n",
      "But the Raven, sitting lonely on the placid bust, spoke only\n",
      "That one word, as if his soul in that one word he did outpour.\n",
      "Nothing further then he uttered – not a feather then he fluttered –\n",
      "Till I scarcely more than muttered \"Other friends have flown before –\n",
      "On the morrow he will leave me, as my hopes have flown before.\"\n",
      "Then the bird said \"Nevermore.\"\n",
      "\n",
      "Startled at the stillness broken by reply so aptly spoken,\n",
      "\"Doubtless,\" said I, \"what it utters is its only stock and store\n",
      "Caught from some unhappy master whom unmerciful Disaster\n",
      "Followed fast and followed faster till his songs one burden bore –\n",
      "Till the dirges of his Hope that melancholy burden bore\n",
      "Of 'Never – nevermore.'\"\n",
      "\n",
      "But the Raven still beguiling my sad fancy into smiling,\n",
      "Straight I wheeled a cushioned seat in front of bird, and bust and door;\n",
      "Then, upon the velvet sinking, I betook myself to linking\n",
      "Fancy unto fancy, thinking what this ominous bird of yore –\n",
      "What this grim, ungainly, ghastly, gaunt and ominous bird of yore\n",
      "Meant in croaking \"Nevermore.\"\n",
      "\n",
      "This I sat engaged in guessing, but no syllable expressing\n",
      "To the fowl whose fiery eyes now burned into my bosom's core;\n",
      "This and more I sat divining, with my head at ease reclining\n",
      "On the cushion's velvet lining that the lamp-light gloated o'er,\n",
      "But whose velvet violet lining with the lamp-light gloating o'er,\n",
      "She shall press, ah, nevermore!\n",
      "\n",
      "Then, methought, the air grew denser, perfumed from an unseen censer\n",
      "Swung by Seraphim whose foot-falls tinkled on the tufted floor.\n",
      "\"Wretch,\" I cried, \"thy God hath lent thee – by these angels he hath sent thee\n",
      "Respite – respite and nepenthe, from thy memories of Lenore;\n",
      "Quaff, oh quaff this kind nepenthe and forget this lost Lenore!\"\n",
      "Quoth the Raven \"Nevermore.\"\n",
      "\n",
      "\"Prophet!\" said I, \"thing of evil! – prophet still, if bird or devil! –\n",
      "Whether Tempter sent, or whether tempest tossed thee here ashore,\n",
      "Desolate yet all undaunted, on this desert land enchanted –\n",
      "On this home by Horror haunted – tell me truly, I implore –\n",
      "Is there – is there balm in Gilead? – tell me – tell me, I implore!\"\n",
      "Quoth the Raven \"Nevermore.\"\n",
      "\n",
      "\"Prophet!\" said I, \"thing of evil – prophet still, if bird or devil!\n",
      "By that Heaven that bends above us – by that God we both adore –\n",
      "Tell this soul with sorrow laden if, within the distant Aidenn,\n",
      "It shall clasp a sainted maiden whom the angels name Lenore –\n",
      "Clasp a rare and radiant maiden whom the angels name Lenore.\"\n",
      "Quoth the Raven \"Nevermore.\"\n",
      "\n",
      "\"Be that word our sign in parting, bird or fiend!\" I shrieked, upstarting –\n",
      "\"Get thee back into the tempest and the Night's Plutonian shore!\n",
      "Leave no black plume as a token of that lie thy soul hath spoken!\n",
      "Leave my loneliness unbroken! – quit the bust above my door!\n",
      "Take thy beak from out my heart, and take thy form from off my door!\"\n",
      "Quoth the Raven \"Nevermore.\"\n",
      "\n",
      "And the Raven, never flitting, still is sitting, still is sitting\n",
      "On the pallid bust of Pallas just above my chamber door;\n",
      "And his eyes have all the seeming of a demon's that is dreaming,\n",
      "And the lamp-light o'er him streaming throws his shadow on the floor;\n",
      "And my soul from out that shadow that lies floating on the floor\n",
      "Shall be lifted – nevermore!\n"
     ]
    }
   ],
   "source": [
    "f=open(\"NLP.txt\",'r')\n",
    "print(f.read())\n",
    "text=list(f.read().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "vocab_size=10000   # Dictionary Size\n",
    "padding_type='pre'\n",
    "max_length_=9      # feature Length\n",
    "oov_tok=\"<oov>\"\n",
    "emb_dim=16         # Embedding Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the Sentences\n",
    "tokenizer=Tokenizer(num_words=vocab_size,oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(text)\n",
    "word_index=tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence=tokenizer.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_new=[]\n",
    "for i in range(1129):\n",
    "    sequence_new.append(sequence[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=[]\n",
    "j=0\n",
    "k=9\n",
    "for i in range(125):\n",
    "    s.append(sequence_new[j:k])\n",
    "    j=k\n",
    "    k=j+9\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 9)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "s=np.array(s)\n",
    "print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=[]\n",
    "i=[]\n",
    "k=2\n",
    "for i in range(125):\n",
    "    a=s[i]\n",
    "    k=2\n",
    "    for j in range(8):\n",
    "        i=a[0:k]\n",
    "        o.append(i)\n",
    "        k=k+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded=pad_sequences(o,maxlen=max_length_,padding=padding_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>167</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>167</td>\n",
       "      <td>168</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>167</td>\n",
       "      <td>168</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>167</td>\n",
       "      <td>168</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>166</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>167</td>\n",
       "      <td>168</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>169</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8\n",
       "0    0    0    0    0    0    0    0  166   44\n",
       "1    0    0    0    0    0    0  166   44   10\n",
       "2    0    0    0    0    0  166   44   10  167\n",
       "3    0    0    0    0  166   44   10  167  168\n",
       "4    0    0    0  166   44   10  167  168   98\n",
       "5    0    0  166   44   10  167  168   98    5\n",
       "6    0  166   44   10  167  168   98    5  169\n",
       "7  166   44   10  167  168   98    5  169  170"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(padded)\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop([8],axis=1)\n",
    "y=df[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.utils as ku \n",
    "label=ku.to_categorical(y,num_classes=len(word_index))\n",
    "xs=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(xs,label,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([  tf.keras.layers.Embedding(vocab_size,128,input_length=(max_length_-1)),\n",
    "                             tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "                            \n",
    "                           tf.keras.layers.Dense(len(word_index),activation='softmax')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "])\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 8, 128)            1280000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 441)               56889     \n",
      "=================================================================\n",
      "Total params: 1,435,705\n",
      "Trainable params: 1,435,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/500\n",
      "700/700 - 1s - loss: 0.0864 - accuracy: 0.9686 - val_loss: 10.1710 - val_accuracy: 0.0733\n",
      "Epoch 2/500\n",
      "700/700 - 1s - loss: 0.0840 - accuracy: 0.9657 - val_loss: 10.1827 - val_accuracy: 0.0733\n",
      "Epoch 3/500\n",
      "700/700 - 1s - loss: 0.0847 - accuracy: 0.9671 - val_loss: 10.1809 - val_accuracy: 0.0733\n",
      "Epoch 4/500\n",
      "700/700 - 1s - loss: 0.0819 - accuracy: 0.9686 - val_loss: 10.1876 - val_accuracy: 0.0667\n",
      "Epoch 5/500\n",
      "700/700 - 1s - loss: 0.0820 - accuracy: 0.9657 - val_loss: 10.2056 - val_accuracy: 0.0733\n",
      "Epoch 6/500\n",
      "700/700 - 1s - loss: 0.0821 - accuracy: 0.9686 - val_loss: 10.1961 - val_accuracy: 0.0700\n",
      "Epoch 7/500\n",
      "700/700 - 1s - loss: 0.0806 - accuracy: 0.9671 - val_loss: 10.2102 - val_accuracy: 0.0733\n",
      "Epoch 8/500\n",
      "700/700 - 1s - loss: 0.0797 - accuracy: 0.9657 - val_loss: 10.2092 - val_accuracy: 0.0700\n",
      "Epoch 9/500\n",
      "700/700 - 1s - loss: 0.0793 - accuracy: 0.9671 - val_loss: 10.2321 - val_accuracy: 0.0733\n",
      "Epoch 10/500\n",
      "700/700 - 1s - loss: 0.0787 - accuracy: 0.9614 - val_loss: 10.2504 - val_accuracy: 0.0700\n",
      "Epoch 11/500\n",
      "700/700 - 1s - loss: 0.0778 - accuracy: 0.9686 - val_loss: 10.2614 - val_accuracy: 0.0667\n",
      "Epoch 12/500\n",
      "700/700 - 1s - loss: 0.0785 - accuracy: 0.9671 - val_loss: 10.2499 - val_accuracy: 0.0700\n",
      "Epoch 13/500\n",
      "700/700 - 1s - loss: 0.0780 - accuracy: 0.9657 - val_loss: 10.2585 - val_accuracy: 0.0733\n",
      "Epoch 14/500\n",
      "700/700 - 1s - loss: 0.0769 - accuracy: 0.9629 - val_loss: 10.2888 - val_accuracy: 0.0700\n",
      "Epoch 15/500\n",
      "700/700 - 1s - loss: 0.0754 - accuracy: 0.9671 - val_loss: 10.2643 - val_accuracy: 0.0767\n",
      "Epoch 16/500\n",
      "700/700 - 1s - loss: 0.0756 - accuracy: 0.9657 - val_loss: 10.3065 - val_accuracy: 0.0667\n",
      "Epoch 17/500\n",
      "700/700 - 1s - loss: 0.0740 - accuracy: 0.9643 - val_loss: 10.2984 - val_accuracy: 0.0767\n",
      "Epoch 18/500\n",
      "700/700 - 1s - loss: 0.0736 - accuracy: 0.9657 - val_loss: 10.3180 - val_accuracy: 0.0733\n",
      "Epoch 19/500\n",
      "700/700 - 1s - loss: 0.0732 - accuracy: 0.9643 - val_loss: 10.3076 - val_accuracy: 0.0700\n",
      "Epoch 20/500\n",
      "700/700 - 1s - loss: 0.0728 - accuracy: 0.9643 - val_loss: 10.3108 - val_accuracy: 0.0767\n",
      "Epoch 21/500\n",
      "700/700 - 1s - loss: 0.0725 - accuracy: 0.9700 - val_loss: 10.3214 - val_accuracy: 0.0733\n",
      "Epoch 22/500\n",
      "700/700 - 1s - loss: 0.0714 - accuracy: 0.9657 - val_loss: 10.3278 - val_accuracy: 0.0700\n",
      "Epoch 23/500\n",
      "700/700 - 1s - loss: 0.0722 - accuracy: 0.9657 - val_loss: 10.3502 - val_accuracy: 0.0667\n",
      "Epoch 24/500\n",
      "700/700 - 1s - loss: 0.0715 - accuracy: 0.9643 - val_loss: 10.3426 - val_accuracy: 0.0733\n",
      "Epoch 25/500\n",
      "700/700 - 1s - loss: 0.0702 - accuracy: 0.9700 - val_loss: 10.3506 - val_accuracy: 0.0700\n",
      "Epoch 26/500\n",
      "700/700 - 1s - loss: 0.0716 - accuracy: 0.9614 - val_loss: 10.3591 - val_accuracy: 0.0700\n",
      "Epoch 27/500\n",
      "700/700 - 1s - loss: 0.0697 - accuracy: 0.9671 - val_loss: 10.3904 - val_accuracy: 0.0700\n",
      "Epoch 28/500\n",
      "700/700 - 1s - loss: 0.0706 - accuracy: 0.9643 - val_loss: 10.3701 - val_accuracy: 0.0700\n",
      "Epoch 29/500\n",
      "700/700 - 1s - loss: 0.0696 - accuracy: 0.9657 - val_loss: 10.3807 - val_accuracy: 0.0700\n",
      "Epoch 30/500\n",
      "700/700 - 1s - loss: 0.0687 - accuracy: 0.9629 - val_loss: 10.4067 - val_accuracy: 0.0733\n",
      "Epoch 31/500\n",
      "700/700 - 1s - loss: 0.0683 - accuracy: 0.9657 - val_loss: 10.4065 - val_accuracy: 0.0700\n",
      "Epoch 32/500\n",
      "700/700 - 1s - loss: 0.0675 - accuracy: 0.9657 - val_loss: 10.4046 - val_accuracy: 0.0733\n",
      "Epoch 33/500\n",
      "700/700 - 1s - loss: 0.0674 - accuracy: 0.9700 - val_loss: 10.4213 - val_accuracy: 0.0700\n",
      "Epoch 34/500\n",
      "700/700 - 1s - loss: 0.0677 - accuracy: 0.9657 - val_loss: 10.4347 - val_accuracy: 0.0700\n",
      "Epoch 35/500\n",
      "700/700 - 1s - loss: 0.0656 - accuracy: 0.9657 - val_loss: 10.4340 - val_accuracy: 0.0667\n",
      "Epoch 36/500\n",
      "700/700 - 0s - loss: 0.0664 - accuracy: 0.9671 - val_loss: 10.4353 - val_accuracy: 0.0700\n",
      "Epoch 37/500\n",
      "700/700 - 1s - loss: 0.0658 - accuracy: 0.9657 - val_loss: 10.4452 - val_accuracy: 0.0700\n",
      "Epoch 38/500\n",
      "700/700 - 1s - loss: 0.0659 - accuracy: 0.9643 - val_loss: 10.4558 - val_accuracy: 0.0700\n",
      "Epoch 39/500\n",
      "700/700 - 0s - loss: 0.0659 - accuracy: 0.9671 - val_loss: 10.4729 - val_accuracy: 0.0700\n",
      "Epoch 40/500\n",
      "700/700 - 1s - loss: 0.0643 - accuracy: 0.9643 - val_loss: 10.4933 - val_accuracy: 0.0700\n",
      "Epoch 41/500\n",
      "700/700 - 1s - loss: 0.0677 - accuracy: 0.9671 - val_loss: 10.4851 - val_accuracy: 0.0733\n",
      "Epoch 42/500\n",
      "700/700 - 1s - loss: 0.1034 - accuracy: 0.9600 - val_loss: 10.3949 - val_accuracy: 0.0733\n",
      "Epoch 43/500\n",
      "700/700 - 1s - loss: 0.2058 - accuracy: 0.9414 - val_loss: 10.3662 - val_accuracy: 0.0800\n",
      "Epoch 44/500\n",
      "700/700 - 1s - loss: 0.3783 - accuracy: 0.9014 - val_loss: 10.2679 - val_accuracy: 0.0633\n",
      "Epoch 45/500\n",
      "700/700 - 1s - loss: 0.3549 - accuracy: 0.9043 - val_loss: 10.0801 - val_accuracy: 0.0533\n",
      "Epoch 46/500\n",
      "700/700 - 1s - loss: 0.2703 - accuracy: 0.9414 - val_loss: 9.9331 - val_accuracy: 0.0667\n",
      "Epoch 47/500\n",
      "700/700 - 1s - loss: 0.1948 - accuracy: 0.9529 - val_loss: 9.9864 - val_accuracy: 0.0733\n",
      "Epoch 48/500\n",
      "700/700 - 1s - loss: 0.1367 - accuracy: 0.9657 - val_loss: 10.1211 - val_accuracy: 0.0667\n",
      "Epoch 49/500\n",
      "700/700 - 1s - loss: 0.1078 - accuracy: 0.9657 - val_loss: 10.2233 - val_accuracy: 0.0600\n",
      "Epoch 50/500\n",
      "700/700 - 1s - loss: 0.0999 - accuracy: 0.9643 - val_loss: 10.1736 - val_accuracy: 0.0567\n",
      "Epoch 51/500\n",
      "700/700 - 1s - loss: 0.0888 - accuracy: 0.9643 - val_loss: 10.2640 - val_accuracy: 0.0633\n",
      "Epoch 52/500\n",
      "700/700 - 1s - loss: 0.0812 - accuracy: 0.9700 - val_loss: 10.3060 - val_accuracy: 0.0567\n",
      "Epoch 53/500\n",
      "700/700 - 1s - loss: 0.0769 - accuracy: 0.9671 - val_loss: 10.3401 - val_accuracy: 0.0567\n",
      "Epoch 54/500\n",
      "700/700 - 1s - loss: 0.0743 - accuracy: 0.9629 - val_loss: 10.3575 - val_accuracy: 0.0567\n",
      "Epoch 55/500\n",
      "700/700 - 1s - loss: 0.0721 - accuracy: 0.9700 - val_loss: 10.3811 - val_accuracy: 0.0600\n",
      "Epoch 56/500\n",
      "700/700 - 1s - loss: 0.0711 - accuracy: 0.9629 - val_loss: 10.3996 - val_accuracy: 0.0567\n",
      "Epoch 57/500\n",
      "700/700 - 0s - loss: 0.0695 - accuracy: 0.9686 - val_loss: 10.4387 - val_accuracy: 0.0567\n",
      "Epoch 58/500\n",
      "700/700 - 1s - loss: 0.0698 - accuracy: 0.9629 - val_loss: 10.4368 - val_accuracy: 0.0633\n",
      "Epoch 59/500\n",
      "700/700 - 0s - loss: 0.0677 - accuracy: 0.9657 - val_loss: 10.4623 - val_accuracy: 0.0567\n",
      "Epoch 60/500\n",
      "700/700 - 1s - loss: 0.0671 - accuracy: 0.9671 - val_loss: 10.4699 - val_accuracy: 0.0600\n",
      "Epoch 61/500\n",
      "700/700 - 0s - loss: 0.0656 - accuracy: 0.9686 - val_loss: 10.5092 - val_accuracy: 0.0633\n",
      "Epoch 62/500\n",
      "700/700 - 1s - loss: 0.0672 - accuracy: 0.9600 - val_loss: 10.5127 - val_accuracy: 0.0600\n",
      "Epoch 63/500\n",
      "700/700 - 0s - loss: 0.0657 - accuracy: 0.9657 - val_loss: 10.5318 - val_accuracy: 0.0600\n",
      "Epoch 64/500\n",
      "700/700 - 1s - loss: 0.0646 - accuracy: 0.9671 - val_loss: 10.5374 - val_accuracy: 0.0633\n",
      "Epoch 65/500\n",
      "700/700 - 1s - loss: 0.0624 - accuracy: 0.9671 - val_loss: 10.5468 - val_accuracy: 0.0633\n",
      "Epoch 66/500\n",
      "700/700 - 0s - loss: 0.0633 - accuracy: 0.9686 - val_loss: 10.5693 - val_accuracy: 0.0600\n",
      "Epoch 67/500\n",
      "700/700 - 0s - loss: 0.0636 - accuracy: 0.9600 - val_loss: 10.5823 - val_accuracy: 0.0633\n",
      "Epoch 68/500\n",
      "700/700 - 1s - loss: 0.0616 - accuracy: 0.9657 - val_loss: 10.5781 - val_accuracy: 0.0633\n",
      "Epoch 69/500\n",
      "700/700 - 1s - loss: 0.0617 - accuracy: 0.9671 - val_loss: 10.6029 - val_accuracy: 0.0600\n",
      "Epoch 70/500\n",
      "700/700 - 1s - loss: 0.0619 - accuracy: 0.9657 - val_loss: 10.6019 - val_accuracy: 0.0633\n",
      "Epoch 71/500\n",
      "700/700 - 0s - loss: 0.0614 - accuracy: 0.9671 - val_loss: 10.6186 - val_accuracy: 0.0633\n",
      "Epoch 72/500\n",
      "700/700 - 0s - loss: 0.0590 - accuracy: 0.9657 - val_loss: 10.6171 - val_accuracy: 0.0633\n",
      "Epoch 73/500\n",
      "700/700 - 1s - loss: 0.0619 - accuracy: 0.9643 - val_loss: 10.6229 - val_accuracy: 0.0667\n",
      "Epoch 74/500\n",
      "700/700 - 1s - loss: 0.0599 - accuracy: 0.9671 - val_loss: 10.6314 - val_accuracy: 0.0633\n",
      "Epoch 75/500\n",
      "700/700 - 1s - loss: 0.0602 - accuracy: 0.9629 - val_loss: 10.6565 - val_accuracy: 0.0633\n",
      "Epoch 76/500\n",
      "700/700 - 0s - loss: 0.0586 - accuracy: 0.9671 - val_loss: 10.6581 - val_accuracy: 0.0633\n",
      "Epoch 77/500\n",
      "700/700 - 0s - loss: 0.0590 - accuracy: 0.9657 - val_loss: 10.6555 - val_accuracy: 0.0633\n",
      "Epoch 78/500\n",
      "700/700 - 1s - loss: 0.0592 - accuracy: 0.9614 - val_loss: 10.6684 - val_accuracy: 0.0667\n",
      "Epoch 79/500\n",
      "700/700 - 1s - loss: 0.0584 - accuracy: 0.9714 - val_loss: 10.6674 - val_accuracy: 0.0667\n",
      "Epoch 80/500\n",
      "700/700 - 0s - loss: 0.0570 - accuracy: 0.9657 - val_loss: 10.6871 - val_accuracy: 0.0633\n",
      "Epoch 81/500\n",
      "700/700 - 1s - loss: 0.0574 - accuracy: 0.9671 - val_loss: 10.7008 - val_accuracy: 0.0633\n",
      "Epoch 82/500\n",
      "700/700 - 1s - loss: 0.0583 - accuracy: 0.9671 - val_loss: 10.6952 - val_accuracy: 0.0633\n",
      "Epoch 83/500\n",
      "700/700 - 0s - loss: 0.0586 - accuracy: 0.9657 - val_loss: 10.7166 - val_accuracy: 0.0633\n",
      "Epoch 84/500\n",
      "700/700 - 0s - loss: 0.0565 - accuracy: 0.9671 - val_loss: 10.6999 - val_accuracy: 0.0633\n",
      "Epoch 85/500\n",
      "700/700 - 0s - loss: 0.0567 - accuracy: 0.9671 - val_loss: 10.7128 - val_accuracy: 0.0633\n",
      "Epoch 86/500\n",
      "700/700 - 0s - loss: 0.0564 - accuracy: 0.9671 - val_loss: 10.7094 - val_accuracy: 0.0633\n",
      "Epoch 87/500\n",
      "700/700 - 1s - loss: 0.0564 - accuracy: 0.9643 - val_loss: 10.7187 - val_accuracy: 0.0633\n",
      "Epoch 88/500\n",
      "700/700 - 1s - loss: 0.0571 - accuracy: 0.9657 - val_loss: 10.7268 - val_accuracy: 0.0633\n",
      "Epoch 89/500\n",
      "700/700 - 1s - loss: 0.0581 - accuracy: 0.9643 - val_loss: 10.7510 - val_accuracy: 0.0633\n",
      "Epoch 90/500\n",
      "700/700 - 1s - loss: 0.0574 - accuracy: 0.9671 - val_loss: 10.7307 - val_accuracy: 0.0667\n",
      "Epoch 91/500\n",
      "700/700 - 1s - loss: 0.0560 - accuracy: 0.9657 - val_loss: 10.7463 - val_accuracy: 0.0633\n",
      "Epoch 92/500\n",
      "700/700 - 1s - loss: 0.0575 - accuracy: 0.9643 - val_loss: 10.7436 - val_accuracy: 0.0667\n",
      "Epoch 93/500\n",
      "700/700 - 1s - loss: 0.0555 - accuracy: 0.9657 - val_loss: 10.7469 - val_accuracy: 0.0633\n",
      "Epoch 94/500\n",
      "700/700 - 1s - loss: 0.0550 - accuracy: 0.9629 - val_loss: 10.7601 - val_accuracy: 0.0633\n",
      "Epoch 95/500\n",
      "700/700 - 0s - loss: 0.0565 - accuracy: 0.9686 - val_loss: 10.7729 - val_accuracy: 0.0633\n",
      "Epoch 96/500\n",
      "700/700 - 0s - loss: 0.0562 - accuracy: 0.9657 - val_loss: 10.7621 - val_accuracy: 0.0633\n",
      "Epoch 97/500\n",
      "700/700 - 0s - loss: 0.0550 - accuracy: 0.9671 - val_loss: 10.7972 - val_accuracy: 0.0633\n",
      "Epoch 98/500\n",
      "700/700 - 0s - loss: 0.0541 - accuracy: 0.9657 - val_loss: 10.7960 - val_accuracy: 0.0633\n",
      "Epoch 99/500\n",
      "700/700 - 0s - loss: 0.0536 - accuracy: 0.9671 - val_loss: 10.8036 - val_accuracy: 0.0633\n",
      "Epoch 100/500\n",
      "700/700 - 1s - loss: 0.0537 - accuracy: 0.9714 - val_loss: 10.8048 - val_accuracy: 0.0667\n",
      "Epoch 101/500\n",
      "700/700 - 1s - loss: 0.0539 - accuracy: 0.9671 - val_loss: 10.8188 - val_accuracy: 0.0667\n",
      "Epoch 102/500\n",
      "700/700 - 0s - loss: 0.0548 - accuracy: 0.9614 - val_loss: 10.8221 - val_accuracy: 0.0667\n",
      "Epoch 103/500\n",
      "700/700 - 0s - loss: 0.0542 - accuracy: 0.9671 - val_loss: 10.8362 - val_accuracy: 0.0633\n",
      "Epoch 104/500\n",
      "700/700 - 0s - loss: 0.0548 - accuracy: 0.9643 - val_loss: 10.8237 - val_accuracy: 0.0633\n",
      "Epoch 105/500\n",
      "700/700 - 1s - loss: 0.0536 - accuracy: 0.9686 - val_loss: 10.8261 - val_accuracy: 0.0633\n",
      "Epoch 106/500\n",
      "700/700 - 1s - loss: 0.0530 - accuracy: 0.9686 - val_loss: 10.8452 - val_accuracy: 0.0667\n",
      "Epoch 107/500\n",
      "700/700 - 1s - loss: 0.0532 - accuracy: 0.9629 - val_loss: 10.8479 - val_accuracy: 0.0633\n",
      "Epoch 108/500\n",
      "700/700 - 1s - loss: 0.0538 - accuracy: 0.9657 - val_loss: 10.8664 - val_accuracy: 0.0633\n",
      "Epoch 109/500\n",
      "700/700 - 1s - loss: 0.0527 - accuracy: 0.9671 - val_loss: 10.8576 - val_accuracy: 0.0633\n",
      "Epoch 110/500\n",
      "700/700 - 1s - loss: 0.0532 - accuracy: 0.9671 - val_loss: 10.8565 - val_accuracy: 0.0633\n",
      "Epoch 111/500\n",
      "700/700 - 1s - loss: 0.0537 - accuracy: 0.9657 - val_loss: 10.8770 - val_accuracy: 0.0667\n",
      "Epoch 112/500\n",
      "700/700 - 1s - loss: 0.0528 - accuracy: 0.9657 - val_loss: 10.8773 - val_accuracy: 0.0633\n",
      "Epoch 113/500\n",
      "700/700 - 1s - loss: 0.0548 - accuracy: 0.9643 - val_loss: 10.8913 - val_accuracy: 0.0633\n",
      "Epoch 114/500\n",
      "700/700 - 1s - loss: 0.0523 - accuracy: 0.9686 - val_loss: 10.8809 - val_accuracy: 0.0633\n",
      "Epoch 115/500\n",
      "700/700 - 1s - loss: 0.0524 - accuracy: 0.9643 - val_loss: 10.8964 - val_accuracy: 0.0667\n",
      "Epoch 116/500\n",
      "700/700 - 0s - loss: 0.0520 - accuracy: 0.9671 - val_loss: 10.8888 - val_accuracy: 0.0667\n",
      "Epoch 117/500\n",
      "700/700 - 0s - loss: 0.0525 - accuracy: 0.9657 - val_loss: 10.9094 - val_accuracy: 0.0667\n",
      "Epoch 118/500\n",
      "700/700 - 0s - loss: 0.0526 - accuracy: 0.9686 - val_loss: 10.9044 - val_accuracy: 0.0667\n",
      "Epoch 119/500\n",
      "700/700 - 1s - loss: 0.0527 - accuracy: 0.9657 - val_loss: 10.9117 - val_accuracy: 0.0633\n",
      "Epoch 120/500\n",
      "700/700 - 1s - loss: 0.0529 - accuracy: 0.9657 - val_loss: 10.9264 - val_accuracy: 0.0667\n",
      "Epoch 121/500\n",
      "700/700 - 1s - loss: 0.0532 - accuracy: 0.9686 - val_loss: 10.9371 - val_accuracy: 0.0667\n",
      "Epoch 122/500\n",
      "700/700 - 0s - loss: 0.0526 - accuracy: 0.9671 - val_loss: 10.9371 - val_accuracy: 0.0667\n",
      "Epoch 123/500\n",
      "700/700 - 0s - loss: 0.0516 - accuracy: 0.9657 - val_loss: 10.9444 - val_accuracy: 0.0667\n",
      "Epoch 124/500\n",
      "700/700 - 0s - loss: 0.0513 - accuracy: 0.9671 - val_loss: 10.9574 - val_accuracy: 0.0667\n",
      "Epoch 125/500\n",
      "700/700 - 1s - loss: 0.0522 - accuracy: 0.9671 - val_loss: 10.9529 - val_accuracy: 0.0667\n",
      "Epoch 126/500\n",
      "700/700 - 1s - loss: 0.0511 - accuracy: 0.9643 - val_loss: 10.9667 - val_accuracy: 0.0700\n",
      "Epoch 127/500\n",
      "700/700 - 1s - loss: 0.0519 - accuracy: 0.9657 - val_loss: 10.9730 - val_accuracy: 0.0700\n",
      "Epoch 128/500\n",
      "700/700 - 1s - loss: 0.0510 - accuracy: 0.9643 - val_loss: 10.9749 - val_accuracy: 0.0667\n",
      "Epoch 129/500\n",
      "700/700 - 1s - loss: 0.0518 - accuracy: 0.9643 - val_loss: 10.9843 - val_accuracy: 0.0667\n",
      "Epoch 130/500\n",
      "700/700 - 1s - loss: 0.0519 - accuracy: 0.9671 - val_loss: 10.9891 - val_accuracy: 0.0667\n",
      "Epoch 131/500\n",
      "700/700 - 1s - loss: 0.0518 - accuracy: 0.9657 - val_loss: 10.9927 - val_accuracy: 0.0667\n",
      "Epoch 132/500\n",
      "700/700 - 1s - loss: 0.0515 - accuracy: 0.9643 - val_loss: 11.0100 - val_accuracy: 0.0667\n",
      "Epoch 133/500\n",
      "700/700 - 1s - loss: 0.0515 - accuracy: 0.9700 - val_loss: 11.0071 - val_accuracy: 0.0667\n",
      "Epoch 134/500\n",
      "700/700 - 0s - loss: 0.0509 - accuracy: 0.9657 - val_loss: 10.9915 - val_accuracy: 0.0700\n",
      "Epoch 135/500\n",
      "700/700 - 1s - loss: 0.0504 - accuracy: 0.9643 - val_loss: 11.0265 - val_accuracy: 0.0667\n",
      "Epoch 136/500\n",
      "700/700 - 1s - loss: 0.0511 - accuracy: 0.9643 - val_loss: 11.0309 - val_accuracy: 0.0667\n",
      "Epoch 137/500\n",
      "700/700 - 1s - loss: 0.0511 - accuracy: 0.9643 - val_loss: 11.0365 - val_accuracy: 0.0667\n",
      "Epoch 138/500\n",
      "700/700 - 1s - loss: 0.0506 - accuracy: 0.9643 - val_loss: 11.0472 - val_accuracy: 0.0667\n",
      "Epoch 139/500\n",
      "700/700 - 1s - loss: 0.0511 - accuracy: 0.9686 - val_loss: 11.0335 - val_accuracy: 0.0667\n",
      "Epoch 140/500\n",
      "700/700 - 1s - loss: 0.0512 - accuracy: 0.9657 - val_loss: 11.0511 - val_accuracy: 0.0667\n",
      "Epoch 141/500\n",
      "700/700 - 1s - loss: 0.0518 - accuracy: 0.9686 - val_loss: 11.0551 - val_accuracy: 0.0667\n",
      "Epoch 142/500\n",
      "700/700 - 1s - loss: 0.0506 - accuracy: 0.9686 - val_loss: 11.0574 - val_accuracy: 0.0667\n",
      "Epoch 143/500\n",
      "700/700 - 1s - loss: 0.0500 - accuracy: 0.9686 - val_loss: 11.0470 - val_accuracy: 0.0667\n",
      "Epoch 144/500\n",
      "700/700 - 1s - loss: 0.0501 - accuracy: 0.9686 - val_loss: 11.0638 - val_accuracy: 0.0667\n",
      "Epoch 145/500\n",
      "700/700 - 1s - loss: 0.0516 - accuracy: 0.9714 - val_loss: 11.0599 - val_accuracy: 0.0667\n",
      "Epoch 146/500\n",
      "700/700 - 1s - loss: 0.0497 - accuracy: 0.9671 - val_loss: 11.0840 - val_accuracy: 0.0667\n",
      "Epoch 147/500\n",
      "700/700 - 1s - loss: 0.0498 - accuracy: 0.9657 - val_loss: 11.0859 - val_accuracy: 0.0667\n",
      "Epoch 148/500\n",
      "700/700 - 0s - loss: 0.0503 - accuracy: 0.9686 - val_loss: 11.0765 - val_accuracy: 0.0667\n",
      "Epoch 149/500\n",
      "700/700 - 0s - loss: 0.0495 - accuracy: 0.9671 - val_loss: 11.0864 - val_accuracy: 0.0700\n",
      "Epoch 150/500\n",
      "700/700 - 0s - loss: 0.0494 - accuracy: 0.9657 - val_loss: 11.0975 - val_accuracy: 0.0667\n",
      "Epoch 151/500\n",
      "700/700 - 1s - loss: 0.0507 - accuracy: 0.9657 - val_loss: 11.1034 - val_accuracy: 0.0667\n",
      "Epoch 152/500\n",
      "700/700 - 1s - loss: 0.0497 - accuracy: 0.9643 - val_loss: 11.1128 - val_accuracy: 0.0667\n",
      "Epoch 153/500\n",
      "700/700 - 1s - loss: 0.0504 - accuracy: 0.9643 - val_loss: 11.1144 - val_accuracy: 0.0667\n",
      "Epoch 154/500\n",
      "700/700 - 1s - loss: 0.0501 - accuracy: 0.9657 - val_loss: 11.1208 - val_accuracy: 0.0667\n",
      "Epoch 155/500\n",
      "700/700 - 1s - loss: 0.0504 - accuracy: 0.9643 - val_loss: 11.1211 - val_accuracy: 0.0667\n",
      "Epoch 156/500\n",
      "700/700 - 1s - loss: 0.0505 - accuracy: 0.9657 - val_loss: 11.1231 - val_accuracy: 0.0667\n",
      "Epoch 157/500\n",
      "700/700 - 1s - loss: 0.0493 - accuracy: 0.9686 - val_loss: 11.1268 - val_accuracy: 0.0667\n",
      "Epoch 158/500\n",
      "700/700 - 1s - loss: 0.0500 - accuracy: 0.9686 - val_loss: 11.1354 - val_accuracy: 0.0700\n",
      "Epoch 159/500\n",
      "700/700 - 1s - loss: 0.0491 - accuracy: 0.9657 - val_loss: 11.1368 - val_accuracy: 0.0667\n",
      "Epoch 160/500\n",
      "700/700 - 1s - loss: 0.0501 - accuracy: 0.9657 - val_loss: 11.1421 - val_accuracy: 0.0667\n",
      "Epoch 161/500\n",
      "700/700 - 1s - loss: 0.0509 - accuracy: 0.9629 - val_loss: 11.1502 - val_accuracy: 0.0667\n",
      "Epoch 162/500\n",
      "700/700 - 1s - loss: 0.0500 - accuracy: 0.9657 - val_loss: 11.1537 - val_accuracy: 0.0667\n",
      "Epoch 163/500\n",
      "700/700 - 1s - loss: 0.0494 - accuracy: 0.9671 - val_loss: 11.1546 - val_accuracy: 0.0667\n",
      "Epoch 164/500\n",
      "700/700 - 1s - loss: 0.0488 - accuracy: 0.9671 - val_loss: 11.1674 - val_accuracy: 0.0667\n",
      "Epoch 165/500\n",
      "700/700 - 1s - loss: 0.0507 - accuracy: 0.9657 - val_loss: 11.1692 - val_accuracy: 0.0667\n",
      "Epoch 166/500\n",
      "700/700 - 1s - loss: 0.0496 - accuracy: 0.9657 - val_loss: 11.1304 - val_accuracy: 0.0667\n",
      "Epoch 167/500\n",
      "700/700 - 1s - loss: 0.0508 - accuracy: 0.9657 - val_loss: 11.1556 - val_accuracy: 0.0667\n",
      "Epoch 168/500\n",
      "700/700 - 1s - loss: 0.0530 - accuracy: 0.9643 - val_loss: 11.1291 - val_accuracy: 0.0633\n",
      "Epoch 169/500\n",
      "700/700 - 1s - loss: 0.0549 - accuracy: 0.9614 - val_loss: 11.1469 - val_accuracy: 0.0633\n",
      "Epoch 170/500\n",
      "700/700 - 1s - loss: 0.0563 - accuracy: 0.9686 - val_loss: 11.1365 - val_accuracy: 0.0533\n",
      "Epoch 171/500\n",
      "700/700 - 1s - loss: 0.0591 - accuracy: 0.9686 - val_loss: 11.1056 - val_accuracy: 0.0700\n",
      "Epoch 172/500\n",
      "700/700 - 1s - loss: 0.0650 - accuracy: 0.9686 - val_loss: 11.0251 - val_accuracy: 0.0700\n",
      "Epoch 173/500\n",
      "700/700 - 1s - loss: 0.0771 - accuracy: 0.9629 - val_loss: 10.9941 - val_accuracy: 0.0600\n",
      "Epoch 174/500\n",
      "700/700 - 1s - loss: 0.0838 - accuracy: 0.9614 - val_loss: 10.9912 - val_accuracy: 0.0733\n",
      "Epoch 175/500\n",
      "700/700 - 1s - loss: 0.1024 - accuracy: 0.9571 - val_loss: 10.9364 - val_accuracy: 0.0667\n",
      "Epoch 176/500\n",
      "700/700 - 1s - loss: 0.0946 - accuracy: 0.9600 - val_loss: 10.9527 - val_accuracy: 0.0600\n",
      "Epoch 177/500\n",
      "700/700 - 1s - loss: 0.1088 - accuracy: 0.9600 - val_loss: 10.8208 - val_accuracy: 0.0667\n",
      "Epoch 178/500\n",
      "700/700 - 1s - loss: 0.1037 - accuracy: 0.9586 - val_loss: 10.8550 - val_accuracy: 0.0700\n",
      "Epoch 179/500\n",
      "700/700 - 1s - loss: 0.0908 - accuracy: 0.9629 - val_loss: 10.9619 - val_accuracy: 0.0767\n",
      "Epoch 180/500\n",
      "700/700 - 1s - loss: 0.0812 - accuracy: 0.9629 - val_loss: 10.9685 - val_accuracy: 0.0633\n",
      "Epoch 181/500\n",
      "700/700 - 1s - loss: 0.0632 - accuracy: 0.9657 - val_loss: 10.9596 - val_accuracy: 0.0767\n",
      "Epoch 182/500\n",
      "700/700 - 1s - loss: 0.0578 - accuracy: 0.9643 - val_loss: 11.0342 - val_accuracy: 0.0767\n",
      "Epoch 183/500\n",
      "700/700 - 0s - loss: 0.0556 - accuracy: 0.9643 - val_loss: 11.0517 - val_accuracy: 0.0767\n",
      "Epoch 184/500\n",
      "700/700 - 1s - loss: 0.0530 - accuracy: 0.9686 - val_loss: 11.0539 - val_accuracy: 0.0767\n",
      "Epoch 185/500\n",
      "700/700 - 1s - loss: 0.0528 - accuracy: 0.9671 - val_loss: 11.0742 - val_accuracy: 0.0733\n",
      "Epoch 186/500\n",
      "700/700 - 0s - loss: 0.0529 - accuracy: 0.9657 - val_loss: 11.0821 - val_accuracy: 0.0733\n",
      "Epoch 187/500\n",
      "700/700 - 0s - loss: 0.0525 - accuracy: 0.9686 - val_loss: 11.0996 - val_accuracy: 0.0733\n",
      "Epoch 188/500\n",
      "700/700 - 1s - loss: 0.0518 - accuracy: 0.9700 - val_loss: 11.1208 - val_accuracy: 0.0733\n",
      "Epoch 189/500\n",
      "700/700 - 0s - loss: 0.0513 - accuracy: 0.9614 - val_loss: 11.1183 - val_accuracy: 0.0733\n",
      "Epoch 190/500\n",
      "700/700 - 1s - loss: 0.0502 - accuracy: 0.9686 - val_loss: 11.1313 - val_accuracy: 0.0733\n",
      "Epoch 191/500\n",
      "700/700 - 0s - loss: 0.0506 - accuracy: 0.9671 - val_loss: 11.1471 - val_accuracy: 0.0733\n",
      "Epoch 192/500\n",
      "700/700 - 1s - loss: 0.0509 - accuracy: 0.9657 - val_loss: 11.1580 - val_accuracy: 0.0733\n",
      "Epoch 193/500\n",
      "700/700 - 0s - loss: 0.0509 - accuracy: 0.9629 - val_loss: 11.1682 - val_accuracy: 0.0733\n",
      "Epoch 194/500\n",
      "700/700 - 1s - loss: 0.0510 - accuracy: 0.9686 - val_loss: 11.1854 - val_accuracy: 0.0733\n",
      "Epoch 195/500\n",
      "700/700 - 0s - loss: 0.0507 - accuracy: 0.9629 - val_loss: 11.1871 - val_accuracy: 0.0733\n",
      "Epoch 196/500\n",
      "700/700 - 0s - loss: 0.0501 - accuracy: 0.9657 - val_loss: 11.1996 - val_accuracy: 0.0733\n",
      "Epoch 197/500\n",
      "700/700 - 1s - loss: 0.0505 - accuracy: 0.9614 - val_loss: 11.2023 - val_accuracy: 0.0733\n",
      "Epoch 198/500\n",
      "700/700 - 1s - loss: 0.0494 - accuracy: 0.9671 - val_loss: 11.2073 - val_accuracy: 0.0700\n",
      "Epoch 199/500\n",
      "700/700 - 0s - loss: 0.0501 - accuracy: 0.9686 - val_loss: 11.2215 - val_accuracy: 0.0733\n",
      "Epoch 200/500\n",
      "700/700 - 1s - loss: 0.0497 - accuracy: 0.9657 - val_loss: 11.2222 - val_accuracy: 0.0733\n",
      "Epoch 201/500\n",
      "700/700 - 1s - loss: 0.0493 - accuracy: 0.9686 - val_loss: 11.2307 - val_accuracy: 0.0767\n",
      "Epoch 202/500\n",
      "700/700 - 1s - loss: 0.0501 - accuracy: 0.9600 - val_loss: 11.2491 - val_accuracy: 0.0733\n",
      "Epoch 203/500\n",
      "700/700 - 1s - loss: 0.0495 - accuracy: 0.9643 - val_loss: 11.2590 - val_accuracy: 0.0767\n",
      "Epoch 204/500\n",
      "700/700 - 1s - loss: 0.0492 - accuracy: 0.9614 - val_loss: 11.2519 - val_accuracy: 0.0700\n",
      "Epoch 205/500\n",
      "700/700 - 0s - loss: 0.0510 - accuracy: 0.9614 - val_loss: 11.2757 - val_accuracy: 0.0700\n",
      "Epoch 206/500\n",
      "700/700 - 0s - loss: 0.0498 - accuracy: 0.9671 - val_loss: 11.2722 - val_accuracy: 0.0733\n",
      "Epoch 207/500\n",
      "700/700 - 1s - loss: 0.0502 - accuracy: 0.9629 - val_loss: 11.2835 - val_accuracy: 0.0700\n",
      "Epoch 208/500\n",
      "700/700 - 1s - loss: 0.0501 - accuracy: 0.9700 - val_loss: 11.2718 - val_accuracy: 0.0733\n",
      "Epoch 209/500\n",
      "700/700 - 0s - loss: 0.0490 - accuracy: 0.9671 - val_loss: 11.2773 - val_accuracy: 0.0700\n",
      "Epoch 210/500\n",
      "700/700 - 0s - loss: 0.0494 - accuracy: 0.9657 - val_loss: 11.2983 - val_accuracy: 0.0700\n",
      "Epoch 211/500\n",
      "700/700 - 1s - loss: 0.0487 - accuracy: 0.9686 - val_loss: 11.3124 - val_accuracy: 0.0700\n",
      "Epoch 212/500\n",
      "700/700 - 1s - loss: 0.0483 - accuracy: 0.9643 - val_loss: 11.3074 - val_accuracy: 0.0700\n",
      "Epoch 213/500\n",
      "700/700 - 0s - loss: 0.0489 - accuracy: 0.9629 - val_loss: 11.3068 - val_accuracy: 0.0700\n",
      "Epoch 214/500\n",
      "700/700 - 1s - loss: 0.0489 - accuracy: 0.9671 - val_loss: 11.3164 - val_accuracy: 0.0700\n",
      "Epoch 215/500\n",
      "700/700 - 1s - loss: 0.0481 - accuracy: 0.9657 - val_loss: 11.3238 - val_accuracy: 0.0733\n",
      "Epoch 216/500\n",
      "700/700 - 1s - loss: 0.0479 - accuracy: 0.9686 - val_loss: 11.3428 - val_accuracy: 0.0700\n",
      "Epoch 217/500\n",
      "700/700 - 1s - loss: 0.0476 - accuracy: 0.9643 - val_loss: 11.3350 - val_accuracy: 0.0700\n",
      "Epoch 218/500\n",
      "700/700 - 1s - loss: 0.0478 - accuracy: 0.9643 - val_loss: 11.3421 - val_accuracy: 0.0700\n",
      "Epoch 219/500\n",
      "700/700 - 1s - loss: 0.0480 - accuracy: 0.9657 - val_loss: 11.3522 - val_accuracy: 0.0700\n",
      "Epoch 220/500\n",
      "700/700 - 0s - loss: 0.0482 - accuracy: 0.9643 - val_loss: 11.3573 - val_accuracy: 0.0700\n",
      "Epoch 221/500\n",
      "700/700 - 0s - loss: 0.0486 - accuracy: 0.9671 - val_loss: 11.3670 - val_accuracy: 0.0700\n",
      "Epoch 222/500\n",
      "700/700 - 1s - loss: 0.0482 - accuracy: 0.9671 - val_loss: 11.3657 - val_accuracy: 0.0700\n",
      "Epoch 223/500\n",
      "700/700 - 0s - loss: 0.0482 - accuracy: 0.9643 - val_loss: 11.3646 - val_accuracy: 0.0733\n",
      "Epoch 224/500\n",
      "700/700 - 0s - loss: 0.0480 - accuracy: 0.9629 - val_loss: 11.3752 - val_accuracy: 0.0700\n",
      "Epoch 225/500\n",
      "700/700 - 1s - loss: 0.0477 - accuracy: 0.9643 - val_loss: 11.3753 - val_accuracy: 0.0700\n",
      "Epoch 226/500\n",
      "700/700 - 0s - loss: 0.0487 - accuracy: 0.9643 - val_loss: 11.3829 - val_accuracy: 0.0700\n",
      "Epoch 227/500\n",
      "700/700 - 1s - loss: 0.0482 - accuracy: 0.9614 - val_loss: 11.3865 - val_accuracy: 0.0700\n",
      "Epoch 228/500\n",
      "700/700 - 1s - loss: 0.0475 - accuracy: 0.9671 - val_loss: 11.3977 - val_accuracy: 0.0700\n",
      "Epoch 229/500\n",
      "700/700 - 1s - loss: 0.0488 - accuracy: 0.9643 - val_loss: 11.3867 - val_accuracy: 0.0733\n",
      "Epoch 230/500\n",
      "700/700 - 1s - loss: 0.0482 - accuracy: 0.9657 - val_loss: 11.4028 - val_accuracy: 0.0700\n",
      "Epoch 231/500\n",
      "700/700 - 1s - loss: 0.0489 - accuracy: 0.9671 - val_loss: 11.4135 - val_accuracy: 0.0700\n",
      "Epoch 232/500\n",
      "700/700 - 1s - loss: 0.0470 - accuracy: 0.9657 - val_loss: 11.4187 - val_accuracy: 0.0700\n",
      "Epoch 233/500\n",
      "700/700 - 1s - loss: 0.0469 - accuracy: 0.9657 - val_loss: 11.4161 - val_accuracy: 0.0700\n",
      "Epoch 234/500\n",
      "700/700 - 0s - loss: 0.0483 - accuracy: 0.9686 - val_loss: 11.4224 - val_accuracy: 0.0700\n",
      "Epoch 235/500\n",
      "700/700 - 1s - loss: 0.0479 - accuracy: 0.9657 - val_loss: 11.4305 - val_accuracy: 0.0700\n",
      "Epoch 236/500\n",
      "700/700 - 1s - loss: 0.0486 - accuracy: 0.9671 - val_loss: 11.4526 - val_accuracy: 0.0700\n",
      "Epoch 237/500\n",
      "700/700 - 1s - loss: 0.0477 - accuracy: 0.9671 - val_loss: 11.4431 - val_accuracy: 0.0733\n",
      "Epoch 238/500\n",
      "700/700 - 1s - loss: 0.0472 - accuracy: 0.9629 - val_loss: 11.4523 - val_accuracy: 0.0700\n",
      "Epoch 239/500\n",
      "700/700 - 1s - loss: 0.0474 - accuracy: 0.9629 - val_loss: 11.4566 - val_accuracy: 0.0700\n",
      "Epoch 240/500\n",
      "700/700 - 1s - loss: 0.0469 - accuracy: 0.9714 - val_loss: 11.4518 - val_accuracy: 0.0700\n",
      "Epoch 241/500\n",
      "700/700 - 1s - loss: 0.0472 - accuracy: 0.9671 - val_loss: 11.4535 - val_accuracy: 0.0733\n",
      "Epoch 242/500\n",
      "700/700 - 0s - loss: 0.0472 - accuracy: 0.9643 - val_loss: 11.4752 - val_accuracy: 0.0700\n",
      "Epoch 243/500\n",
      "700/700 - 0s - loss: 0.0472 - accuracy: 0.9671 - val_loss: 11.4746 - val_accuracy: 0.0700\n",
      "Epoch 244/500\n",
      "700/700 - 0s - loss: 0.0476 - accuracy: 0.9671 - val_loss: 11.4752 - val_accuracy: 0.0733\n",
      "Epoch 245/500\n",
      "700/700 - 0s - loss: 0.0480 - accuracy: 0.9657 - val_loss: 11.4810 - val_accuracy: 0.0700\n",
      "Epoch 246/500\n",
      "700/700 - 1s - loss: 0.0489 - accuracy: 0.9657 - val_loss: 11.5039 - val_accuracy: 0.0700\n",
      "Epoch 247/500\n",
      "700/700 - 1s - loss: 0.0475 - accuracy: 0.9671 - val_loss: 11.4957 - val_accuracy: 0.0700\n",
      "Epoch 248/500\n",
      "700/700 - 1s - loss: 0.0470 - accuracy: 0.9657 - val_loss: 11.4797 - val_accuracy: 0.0700\n",
      "Epoch 249/500\n",
      "700/700 - 1s - loss: 0.0478 - accuracy: 0.9657 - val_loss: 11.5144 - val_accuracy: 0.0733\n",
      "Epoch 250/500\n",
      "700/700 - 0s - loss: 0.0483 - accuracy: 0.9657 - val_loss: 11.5035 - val_accuracy: 0.0700\n",
      "Epoch 251/500\n",
      "700/700 - 0s - loss: 0.0466 - accuracy: 0.9671 - val_loss: 11.5093 - val_accuracy: 0.0700\n",
      "Epoch 252/500\n",
      "700/700 - 1s - loss: 0.0470 - accuracy: 0.9671 - val_loss: 11.5102 - val_accuracy: 0.0733\n",
      "Epoch 253/500\n",
      "700/700 - 0s - loss: 0.0473 - accuracy: 0.9643 - val_loss: 11.5263 - val_accuracy: 0.0700\n",
      "Epoch 254/500\n",
      "700/700 - 1s - loss: 0.0477 - accuracy: 0.9657 - val_loss: 11.5369 - val_accuracy: 0.0700\n",
      "Epoch 255/500\n",
      "700/700 - 1s - loss: 0.0476 - accuracy: 0.9671 - val_loss: 11.5374 - val_accuracy: 0.0700\n",
      "Epoch 256/500\n",
      "700/700 - 1s - loss: 0.0471 - accuracy: 0.9643 - val_loss: 11.5251 - val_accuracy: 0.0700\n",
      "Epoch 257/500\n",
      "700/700 - 1s - loss: 0.0484 - accuracy: 0.9643 - val_loss: 11.5545 - val_accuracy: 0.0700\n",
      "Epoch 258/500\n",
      "700/700 - 1s - loss: 0.0463 - accuracy: 0.9700 - val_loss: 11.5429 - val_accuracy: 0.0700\n",
      "Epoch 259/500\n",
      "700/700 - 1s - loss: 0.0470 - accuracy: 0.9671 - val_loss: 11.5420 - val_accuracy: 0.0700\n",
      "Epoch 260/500\n",
      "700/700 - 0s - loss: 0.0478 - accuracy: 0.9657 - val_loss: 11.5621 - val_accuracy: 0.0700\n",
      "Epoch 261/500\n",
      "700/700 - 0s - loss: 0.0465 - accuracy: 0.9643 - val_loss: 11.5506 - val_accuracy: 0.0700\n",
      "Epoch 262/500\n",
      "700/700 - 1s - loss: 0.0474 - accuracy: 0.9629 - val_loss: 11.5700 - val_accuracy: 0.0700\n",
      "Epoch 263/500\n",
      "700/700 - 1s - loss: 0.0465 - accuracy: 0.9657 - val_loss: 11.5655 - val_accuracy: 0.0700\n",
      "Epoch 264/500\n",
      "700/700 - 1s - loss: 0.0472 - accuracy: 0.9643 - val_loss: 11.5746 - val_accuracy: 0.0733\n",
      "Epoch 265/500\n",
      "700/700 - 1s - loss: 0.0474 - accuracy: 0.9657 - val_loss: 11.5820 - val_accuracy: 0.0700\n",
      "Epoch 266/500\n",
      "700/700 - 1s - loss: 0.0472 - accuracy: 0.9657 - val_loss: 11.5917 - val_accuracy: 0.0733\n",
      "Epoch 267/500\n",
      "700/700 - 0s - loss: 0.0480 - accuracy: 0.9600 - val_loss: 11.5925 - val_accuracy: 0.0700\n",
      "Epoch 268/500\n",
      "700/700 - 1s - loss: 0.0470 - accuracy: 0.9657 - val_loss: 11.5877 - val_accuracy: 0.0700\n",
      "Epoch 269/500\n",
      "700/700 - 0s - loss: 0.0470 - accuracy: 0.9700 - val_loss: 11.5824 - val_accuracy: 0.0700\n",
      "Epoch 270/500\n",
      "700/700 - 1s - loss: 0.0457 - accuracy: 0.9657 - val_loss: 11.6098 - val_accuracy: 0.0700\n",
      "Epoch 271/500\n",
      "700/700 - 0s - loss: 0.0478 - accuracy: 0.9629 - val_loss: 11.6161 - val_accuracy: 0.0700\n",
      "Epoch 272/500\n",
      "700/700 - 1s - loss: 0.0472 - accuracy: 0.9657 - val_loss: 11.6266 - val_accuracy: 0.0700\n",
      "Epoch 273/500\n",
      "700/700 - 1s - loss: 0.0470 - accuracy: 0.9643 - val_loss: 11.6177 - val_accuracy: 0.0733\n",
      "Epoch 274/500\n",
      "700/700 - 0s - loss: 0.0464 - accuracy: 0.9643 - val_loss: 11.6198 - val_accuracy: 0.0733\n",
      "Epoch 275/500\n",
      "700/700 - 1s - loss: 0.0467 - accuracy: 0.9657 - val_loss: 11.6293 - val_accuracy: 0.0733\n",
      "Epoch 276/500\n",
      "700/700 - 1s - loss: 0.0485 - accuracy: 0.9643 - val_loss: 11.6471 - val_accuracy: 0.0700\n",
      "Epoch 277/500\n",
      "700/700 - 1s - loss: 0.0472 - accuracy: 0.9643 - val_loss: 11.6409 - val_accuracy: 0.0700\n",
      "Epoch 278/500\n",
      "700/700 - 1s - loss: 0.0478 - accuracy: 0.9671 - val_loss: 11.6394 - val_accuracy: 0.0733\n",
      "Epoch 279/500\n",
      "700/700 - 1s - loss: 0.0473 - accuracy: 0.9671 - val_loss: 11.6334 - val_accuracy: 0.0700\n",
      "Epoch 280/500\n",
      "700/700 - 1s - loss: 0.0474 - accuracy: 0.9643 - val_loss: 11.6603 - val_accuracy: 0.0700\n",
      "Epoch 281/500\n",
      "700/700 - 1s - loss: 0.0472 - accuracy: 0.9671 - val_loss: 11.6672 - val_accuracy: 0.0700\n",
      "Epoch 282/500\n",
      "700/700 - 1s - loss: 0.0461 - accuracy: 0.9686 - val_loss: 11.6583 - val_accuracy: 0.0700\n",
      "Epoch 283/500\n",
      "700/700 - 0s - loss: 0.0473 - accuracy: 0.9657 - val_loss: 11.6559 - val_accuracy: 0.0733\n",
      "Epoch 284/500\n",
      "700/700 - 0s - loss: 0.0472 - accuracy: 0.9629 - val_loss: 11.6669 - val_accuracy: 0.0700\n",
      "Epoch 285/500\n",
      "700/700 - 1s - loss: 0.0464 - accuracy: 0.9700 - val_loss: 11.6781 - val_accuracy: 0.0733\n",
      "Epoch 286/500\n",
      "700/700 - 1s - loss: 0.0463 - accuracy: 0.9671 - val_loss: 11.6873 - val_accuracy: 0.0700\n",
      "Epoch 287/500\n",
      "700/700 - 1s - loss: 0.0464 - accuracy: 0.9671 - val_loss: 11.6807 - val_accuracy: 0.0700\n",
      "Epoch 288/500\n",
      "700/700 - 1s - loss: 0.0466 - accuracy: 0.9671 - val_loss: 11.6886 - val_accuracy: 0.0733\n",
      "Epoch 289/500\n",
      "700/700 - 1s - loss: 0.0470 - accuracy: 0.9657 - val_loss: 11.6884 - val_accuracy: 0.0700\n",
      "Epoch 290/500\n",
      "700/700 - 1s - loss: 0.0464 - accuracy: 0.9686 - val_loss: 11.6971 - val_accuracy: 0.0733\n",
      "Epoch 291/500\n",
      "700/700 - 1s - loss: 0.0469 - accuracy: 0.9700 - val_loss: 11.7020 - val_accuracy: 0.0733\n",
      "Epoch 292/500\n",
      "700/700 - 1s - loss: 0.0466 - accuracy: 0.9671 - val_loss: 11.7056 - val_accuracy: 0.0700\n",
      "Epoch 293/500\n",
      "700/700 - 1s - loss: 0.0458 - accuracy: 0.9671 - val_loss: 11.7052 - val_accuracy: 0.0700\n",
      "Epoch 294/500\n",
      "700/700 - 0s - loss: 0.0461 - accuracy: 0.9700 - val_loss: 11.7197 - val_accuracy: 0.0700\n",
      "Epoch 295/500\n",
      "700/700 - 0s - loss: 0.0465 - accuracy: 0.9600 - val_loss: 11.7201 - val_accuracy: 0.0700\n",
      "Epoch 296/500\n",
      "700/700 - 1s - loss: 0.0471 - accuracy: 0.9671 - val_loss: 11.7333 - val_accuracy: 0.0700\n",
      "Epoch 297/500\n",
      "700/700 - 1s - loss: 0.0474 - accuracy: 0.9671 - val_loss: 11.7469 - val_accuracy: 0.0700\n",
      "Epoch 298/500\n",
      "700/700 - 1s - loss: 0.0467 - accuracy: 0.9671 - val_loss: 11.7298 - val_accuracy: 0.0700\n",
      "Epoch 299/500\n",
      "700/700 - 1s - loss: 0.0475 - accuracy: 0.9686 - val_loss: 11.7449 - val_accuracy: 0.0700\n",
      "Epoch 300/500\n",
      "700/700 - 1s - loss: 0.0473 - accuracy: 0.9671 - val_loss: 11.7380 - val_accuracy: 0.0733\n",
      "Epoch 301/500\n",
      "700/700 - 1s - loss: 0.0466 - accuracy: 0.9629 - val_loss: 11.7422 - val_accuracy: 0.0700\n",
      "Epoch 302/500\n",
      "700/700 - 1s - loss: 0.0475 - accuracy: 0.9671 - val_loss: 11.7483 - val_accuracy: 0.0700\n",
      "Epoch 303/500\n",
      "700/700 - 1s - loss: 0.0461 - accuracy: 0.9643 - val_loss: 11.7537 - val_accuracy: 0.0733\n",
      "Epoch 304/500\n",
      "700/700 - 1s - loss: 0.0459 - accuracy: 0.9657 - val_loss: 11.7556 - val_accuracy: 0.0700\n",
      "Epoch 305/500\n",
      "700/700 - 1s - loss: 0.0461 - accuracy: 0.9671 - val_loss: 11.7613 - val_accuracy: 0.0700\n",
      "Epoch 306/500\n",
      "700/700 - 1s - loss: 0.0469 - accuracy: 0.9657 - val_loss: 11.7544 - val_accuracy: 0.0700\n",
      "Epoch 307/500\n",
      "700/700 - 1s - loss: 0.0464 - accuracy: 0.9643 - val_loss: 11.7818 - val_accuracy: 0.0700\n",
      "Epoch 308/500\n",
      "700/700 - 1s - loss: 0.0461 - accuracy: 0.9657 - val_loss: 11.7663 - val_accuracy: 0.0733\n",
      "Epoch 309/500\n",
      "700/700 - 1s - loss: 0.0464 - accuracy: 0.9671 - val_loss: 11.7806 - val_accuracy: 0.0700\n",
      "Epoch 310/500\n",
      "700/700 - 1s - loss: 0.0463 - accuracy: 0.9657 - val_loss: 11.7874 - val_accuracy: 0.0700\n",
      "Epoch 311/500\n",
      "700/700 - 0s - loss: 0.0463 - accuracy: 0.9686 - val_loss: 11.8031 - val_accuracy: 0.0700\n",
      "Epoch 312/500\n",
      "700/700 - 1s - loss: 0.0463 - accuracy: 0.9657 - val_loss: 11.8047 - val_accuracy: 0.0700\n",
      "Epoch 313/500\n",
      "700/700 - 1s - loss: 0.0473 - accuracy: 0.9629 - val_loss: 11.8018 - val_accuracy: 0.0733\n",
      "Epoch 314/500\n",
      "700/700 - 0s - loss: 0.0459 - accuracy: 0.9686 - val_loss: 11.8006 - val_accuracy: 0.0700\n",
      "Epoch 315/500\n",
      "700/700 - 1s - loss: 0.0462 - accuracy: 0.9686 - val_loss: 11.8027 - val_accuracy: 0.0733\n",
      "Epoch 316/500\n",
      "700/700 - 1s - loss: 0.0458 - accuracy: 0.9714 - val_loss: 11.8222 - val_accuracy: 0.0700\n",
      "Epoch 317/500\n",
      "700/700 - 1s - loss: 0.0471 - accuracy: 0.9686 - val_loss: 11.8048 - val_accuracy: 0.0700\n",
      "Epoch 318/500\n",
      "700/700 - 1s - loss: 0.0461 - accuracy: 0.9671 - val_loss: 11.8288 - val_accuracy: 0.0700\n",
      "Epoch 319/500\n",
      "700/700 - 1s - loss: 0.0461 - accuracy: 0.9643 - val_loss: 11.8305 - val_accuracy: 0.0733\n",
      "Epoch 320/500\n",
      "700/700 - 1s - loss: 0.0460 - accuracy: 0.9671 - val_loss: 11.8319 - val_accuracy: 0.0700\n",
      "Epoch 321/500\n",
      "700/700 - 1s - loss: 0.0457 - accuracy: 0.9700 - val_loss: 11.8303 - val_accuracy: 0.0700\n",
      "Epoch 322/500\n",
      "700/700 - 1s - loss: 0.0470 - accuracy: 0.9643 - val_loss: 11.8509 - val_accuracy: 0.0700\n",
      "Epoch 323/500\n",
      "700/700 - 1s - loss: 0.0467 - accuracy: 0.9629 - val_loss: 11.8424 - val_accuracy: 0.0700\n",
      "Epoch 324/500\n",
      "700/700 - 1s - loss: 0.0463 - accuracy: 0.9700 - val_loss: 11.8446 - val_accuracy: 0.0733\n",
      "Epoch 325/500\n",
      "700/700 - 1s - loss: 0.0465 - accuracy: 0.9643 - val_loss: 11.8615 - val_accuracy: 0.0733\n",
      "Epoch 326/500\n",
      "700/700 - 1s - loss: 0.0465 - accuracy: 0.9671 - val_loss: 11.8660 - val_accuracy: 0.0733\n",
      "Epoch 327/500\n",
      "700/700 - 1s - loss: 0.0461 - accuracy: 0.9671 - val_loss: 11.8561 - val_accuracy: 0.0700\n",
      "Epoch 328/500\n",
      "700/700 - 1s - loss: 0.0459 - accuracy: 0.9700 - val_loss: 11.8634 - val_accuracy: 0.0700\n",
      "Epoch 329/500\n",
      "700/700 - 1s - loss: 0.0461 - accuracy: 0.9671 - val_loss: 11.8814 - val_accuracy: 0.0700\n",
      "Epoch 330/500\n",
      "700/700 - 1s - loss: 0.0456 - accuracy: 0.9657 - val_loss: 11.8805 - val_accuracy: 0.0733\n",
      "Epoch 331/500\n",
      "700/700 - 1s - loss: 0.0455 - accuracy: 0.9671 - val_loss: 11.8850 - val_accuracy: 0.0700\n",
      "Epoch 332/500\n",
      "700/700 - 1s - loss: 0.0459 - accuracy: 0.9686 - val_loss: 11.8866 - val_accuracy: 0.0700\n",
      "Epoch 333/500\n",
      "700/700 - 1s - loss: 0.0455 - accuracy: 0.9657 - val_loss: 11.8884 - val_accuracy: 0.0700\n",
      "Epoch 334/500\n",
      "700/700 - 1s - loss: 0.0466 - accuracy: 0.9657 - val_loss: 11.8937 - val_accuracy: 0.0700\n",
      "Epoch 335/500\n",
      "700/700 - 1s - loss: 0.0457 - accuracy: 0.9700 - val_loss: 11.9122 - val_accuracy: 0.0700\n",
      "Epoch 336/500\n",
      "700/700 - 1s - loss: 0.0457 - accuracy: 0.9686 - val_loss: 11.9056 - val_accuracy: 0.0700\n",
      "Epoch 337/500\n",
      "700/700 - 1s - loss: 0.0463 - accuracy: 0.9657 - val_loss: 11.9055 - val_accuracy: 0.0700\n",
      "Epoch 338/500\n",
      "700/700 - 0s - loss: 0.0462 - accuracy: 0.9657 - val_loss: 11.9152 - val_accuracy: 0.0700\n",
      "Epoch 339/500\n",
      "700/700 - 1s - loss: 0.0460 - accuracy: 0.9671 - val_loss: 11.9083 - val_accuracy: 0.0700\n",
      "Epoch 340/500\n",
      "700/700 - 1s - loss: 0.0450 - accuracy: 0.9700 - val_loss: 11.9170 - val_accuracy: 0.0700\n",
      "Epoch 341/500\n",
      "700/700 - 0s - loss: 0.0467 - accuracy: 0.9629 - val_loss: 11.9285 - val_accuracy: 0.0700\n",
      "Epoch 342/500\n",
      "700/700 - 1s - loss: 0.0460 - accuracy: 0.9671 - val_loss: 11.9210 - val_accuracy: 0.0700\n",
      "Epoch 343/500\n",
      "700/700 - 0s - loss: 0.0466 - accuracy: 0.9643 - val_loss: 11.9223 - val_accuracy: 0.0700\n",
      "Epoch 344/500\n",
      "700/700 - 1s - loss: 0.0460 - accuracy: 0.9671 - val_loss: 11.9479 - val_accuracy: 0.0700\n",
      "Epoch 345/500\n",
      "700/700 - 1s - loss: 0.0454 - accuracy: 0.9643 - val_loss: 11.9331 - val_accuracy: 0.0700\n",
      "Epoch 346/500\n",
      "700/700 - 0s - loss: 0.0451 - accuracy: 0.9643 - val_loss: 11.9475 - val_accuracy: 0.0700\n",
      "Epoch 347/500\n",
      "700/700 - 1s - loss: 0.0460 - accuracy: 0.9686 - val_loss: 11.9484 - val_accuracy: 0.0700\n",
      "Epoch 348/500\n",
      "700/700 - 0s - loss: 0.0458 - accuracy: 0.9671 - val_loss: 11.9576 - val_accuracy: 0.0733\n",
      "Epoch 349/500\n",
      "700/700 - 1s - loss: 0.0458 - accuracy: 0.9643 - val_loss: 11.9658 - val_accuracy: 0.0700\n",
      "Epoch 350/500\n",
      "700/700 - 1s - loss: 0.0462 - accuracy: 0.9714 - val_loss: 11.9553 - val_accuracy: 0.0700\n",
      "Epoch 351/500\n",
      "700/700 - 1s - loss: 0.0467 - accuracy: 0.9643 - val_loss: 11.9747 - val_accuracy: 0.0733\n",
      "Epoch 352/500\n",
      "700/700 - 1s - loss: 0.0461 - accuracy: 0.9671 - val_loss: 11.9721 - val_accuracy: 0.0733\n",
      "Epoch 353/500\n",
      "700/700 - 0s - loss: 0.0457 - accuracy: 0.9643 - val_loss: 11.9669 - val_accuracy: 0.0700\n",
      "Epoch 354/500\n",
      "700/700 - 1s - loss: 0.0460 - accuracy: 0.9686 - val_loss: 11.9817 - val_accuracy: 0.0733\n",
      "Epoch 355/500\n",
      "700/700 - 1s - loss: 0.0455 - accuracy: 0.9657 - val_loss: 11.9780 - val_accuracy: 0.0700\n",
      "Epoch 356/500\n",
      "700/700 - 1s - loss: 0.0457 - accuracy: 0.9629 - val_loss: 11.9771 - val_accuracy: 0.0700\n",
      "Epoch 357/500\n",
      "700/700 - 1s - loss: 0.0462 - accuracy: 0.9643 - val_loss: 11.9886 - val_accuracy: 0.0700\n",
      "Epoch 358/500\n",
      "700/700 - 1s - loss: 0.0464 - accuracy: 0.9657 - val_loss: 12.0018 - val_accuracy: 0.0700\n",
      "Epoch 359/500\n",
      "700/700 - 1s - loss: 0.0456 - accuracy: 0.9671 - val_loss: 11.9746 - val_accuracy: 0.0700\n",
      "Epoch 360/500\n",
      "700/700 - 0s - loss: 0.0469 - accuracy: 0.9671 - val_loss: 11.9398 - val_accuracy: 0.0767\n",
      "Epoch 361/500\n",
      "700/700 - 1s - loss: 0.0860 - accuracy: 0.9571 - val_loss: 11.7625 - val_accuracy: 0.0700\n",
      "Epoch 362/500\n",
      "700/700 - 1s - loss: 0.1377 - accuracy: 0.9457 - val_loss: 11.4256 - val_accuracy: 0.0500\n",
      "Epoch 363/500\n",
      "700/700 - 1s - loss: 0.1900 - accuracy: 0.9343 - val_loss: 11.0533 - val_accuracy: 0.0600\n",
      "Epoch 364/500\n",
      "700/700 - 1s - loss: 0.1765 - accuracy: 0.9414 - val_loss: 10.9259 - val_accuracy: 0.0733\n",
      "Epoch 365/500\n",
      "700/700 - 1s - loss: 0.1170 - accuracy: 0.9614 - val_loss: 10.8120 - val_accuracy: 0.0600\n",
      "Epoch 366/500\n",
      "700/700 - 1s - loss: 0.1023 - accuracy: 0.9571 - val_loss: 10.9899 - val_accuracy: 0.0733\n",
      "Epoch 367/500\n",
      "700/700 - 1s - loss: 0.0769 - accuracy: 0.9557 - val_loss: 10.9387 - val_accuracy: 0.0633\n",
      "Epoch 368/500\n",
      "700/700 - 0s - loss: 0.0645 - accuracy: 0.9614 - val_loss: 10.9550 - val_accuracy: 0.0667\n",
      "Epoch 369/500\n",
      "700/700 - 1s - loss: 0.0540 - accuracy: 0.9643 - val_loss: 10.9776 - val_accuracy: 0.0633\n",
      "Epoch 370/500\n",
      "700/700 - 1s - loss: 0.0530 - accuracy: 0.9714 - val_loss: 11.0232 - val_accuracy: 0.0700\n",
      "Epoch 371/500\n",
      "700/700 - 1s - loss: 0.0529 - accuracy: 0.9671 - val_loss: 11.0444 - val_accuracy: 0.0700\n",
      "Epoch 372/500\n",
      "700/700 - 0s - loss: 0.0514 - accuracy: 0.9671 - val_loss: 11.0915 - val_accuracy: 0.0700\n",
      "Epoch 373/500\n",
      "700/700 - 1s - loss: 0.0508 - accuracy: 0.9643 - val_loss: 11.1179 - val_accuracy: 0.0700\n",
      "Epoch 374/500\n",
      "700/700 - 1s - loss: 0.0513 - accuracy: 0.9614 - val_loss: 11.1382 - val_accuracy: 0.0667\n",
      "Epoch 375/500\n",
      "700/700 - 1s - loss: 0.0493 - accuracy: 0.9657 - val_loss: 11.1447 - val_accuracy: 0.0700\n",
      "Epoch 376/500\n",
      "700/700 - 1s - loss: 0.0500 - accuracy: 0.9657 - val_loss: 11.1618 - val_accuracy: 0.0667\n",
      "Epoch 377/500\n",
      "700/700 - 1s - loss: 0.0497 - accuracy: 0.9671 - val_loss: 11.1936 - val_accuracy: 0.0667\n",
      "Epoch 378/500\n",
      "700/700 - 1s - loss: 0.0498 - accuracy: 0.9629 - val_loss: 11.2046 - val_accuracy: 0.0700\n",
      "Epoch 379/500\n",
      "700/700 - 0s - loss: 0.0482 - accuracy: 0.9686 - val_loss: 11.2115 - val_accuracy: 0.0700\n",
      "Epoch 380/500\n",
      "700/700 - 1s - loss: 0.0478 - accuracy: 0.9686 - val_loss: 11.2311 - val_accuracy: 0.0700\n",
      "Epoch 381/500\n",
      "700/700 - 1s - loss: 0.0482 - accuracy: 0.9657 - val_loss: 11.2451 - val_accuracy: 0.0700\n",
      "Epoch 382/500\n",
      "700/700 - 1s - loss: 0.0488 - accuracy: 0.9629 - val_loss: 11.2482 - val_accuracy: 0.0767\n",
      "Epoch 383/500\n",
      "700/700 - 1s - loss: 0.0481 - accuracy: 0.9643 - val_loss: 11.2678 - val_accuracy: 0.0700\n",
      "Epoch 384/500\n",
      "700/700 - 1s - loss: 0.0477 - accuracy: 0.9643 - val_loss: 11.2698 - val_accuracy: 0.0700\n",
      "Epoch 385/500\n",
      "700/700 - 1s - loss: 0.0477 - accuracy: 0.9671 - val_loss: 11.2892 - val_accuracy: 0.0700\n",
      "Epoch 386/500\n",
      "700/700 - 1s - loss: 0.0479 - accuracy: 0.9643 - val_loss: 11.3047 - val_accuracy: 0.0700\n",
      "Epoch 387/500\n",
      "700/700 - 1s - loss: 0.0481 - accuracy: 0.9643 - val_loss: 11.3116 - val_accuracy: 0.0700\n",
      "Epoch 388/500\n",
      "700/700 - 1s - loss: 0.0474 - accuracy: 0.9686 - val_loss: 11.3081 - val_accuracy: 0.0733\n",
      "Epoch 389/500\n",
      "700/700 - 1s - loss: 0.0473 - accuracy: 0.9686 - val_loss: 11.3162 - val_accuracy: 0.0733\n",
      "Epoch 390/500\n",
      "700/700 - 1s - loss: 0.0476 - accuracy: 0.9657 - val_loss: 11.3360 - val_accuracy: 0.0700\n",
      "Epoch 391/500\n",
      "700/700 - 1s - loss: 0.0474 - accuracy: 0.9657 - val_loss: 11.3560 - val_accuracy: 0.0700\n",
      "Epoch 392/500\n",
      "700/700 - 1s - loss: 0.0479 - accuracy: 0.9643 - val_loss: 11.3644 - val_accuracy: 0.0700\n",
      "Epoch 393/500\n",
      "700/700 - 1s - loss: 0.0467 - accuracy: 0.9671 - val_loss: 11.3624 - val_accuracy: 0.0700\n",
      "Epoch 394/500\n",
      "700/700 - 1s - loss: 0.0462 - accuracy: 0.9671 - val_loss: 11.3689 - val_accuracy: 0.0700\n",
      "Epoch 395/500\n",
      "700/700 - 1s - loss: 0.0474 - accuracy: 0.9643 - val_loss: 11.3805 - val_accuracy: 0.0700\n",
      "Epoch 396/500\n",
      "700/700 - 1s - loss: 0.0469 - accuracy: 0.9700 - val_loss: 11.3860 - val_accuracy: 0.0733\n",
      "Epoch 397/500\n",
      "700/700 - 1s - loss: 0.0475 - accuracy: 0.9686 - val_loss: 11.3933 - val_accuracy: 0.0767\n",
      "Epoch 398/500\n",
      "700/700 - 1s - loss: 0.0478 - accuracy: 0.9657 - val_loss: 11.4016 - val_accuracy: 0.0700\n",
      "Epoch 399/500\n",
      "700/700 - 1s - loss: 0.0480 - accuracy: 0.9629 - val_loss: 11.4034 - val_accuracy: 0.0700\n",
      "Epoch 400/500\n",
      "700/700 - 1s - loss: 0.0473 - accuracy: 0.9657 - val_loss: 11.4229 - val_accuracy: 0.0733\n",
      "Epoch 401/500\n",
      "700/700 - 1s - loss: 0.0459 - accuracy: 0.9657 - val_loss: 11.4270 - val_accuracy: 0.0733\n",
      "Epoch 402/500\n",
      "700/700 - 1s - loss: 0.0466 - accuracy: 0.9686 - val_loss: 11.4330 - val_accuracy: 0.0733\n",
      "Epoch 403/500\n",
      "700/700 - 1s - loss: 0.0468 - accuracy: 0.9629 - val_loss: 11.4442 - val_accuracy: 0.0733\n",
      "Epoch 404/500\n",
      "700/700 - 0s - loss: 0.0465 - accuracy: 0.9657 - val_loss: 11.4532 - val_accuracy: 0.0733\n",
      "Epoch 405/500\n",
      "700/700 - 1s - loss: 0.0467 - accuracy: 0.9657 - val_loss: 11.4568 - val_accuracy: 0.0767\n",
      "Epoch 406/500\n",
      "700/700 - 1s - loss: 0.0469 - accuracy: 0.9671 - val_loss: 11.4669 - val_accuracy: 0.0733\n",
      "Epoch 407/500\n",
      "700/700 - 1s - loss: 0.0464 - accuracy: 0.9671 - val_loss: 11.4613 - val_accuracy: 0.0767\n",
      "Epoch 408/500\n",
      "700/700 - 1s - loss: 0.0473 - accuracy: 0.9657 - val_loss: 11.4796 - val_accuracy: 0.0767\n",
      "Epoch 409/500\n",
      "700/700 - 1s - loss: 0.0467 - accuracy: 0.9686 - val_loss: 11.4800 - val_accuracy: 0.0733\n",
      "Epoch 410/500\n",
      "700/700 - 1s - loss: 0.0470 - accuracy: 0.9686 - val_loss: 11.4885 - val_accuracy: 0.0733\n",
      "Epoch 411/500\n",
      "700/700 - 1s - loss: 0.0470 - accuracy: 0.9657 - val_loss: 11.4959 - val_accuracy: 0.0733\n",
      "Epoch 412/500\n",
      "700/700 - 1s - loss: 0.0472 - accuracy: 0.9643 - val_loss: 11.4984 - val_accuracy: 0.0733\n",
      "Epoch 413/500\n",
      "700/700 - 1s - loss: 0.0468 - accuracy: 0.9614 - val_loss: 11.5115 - val_accuracy: 0.0733\n",
      "Epoch 414/500\n",
      "700/700 - 1s - loss: 0.0467 - accuracy: 0.9657 - val_loss: 11.5180 - val_accuracy: 0.0733\n",
      "Epoch 415/500\n",
      "700/700 - 1s - loss: 0.0459 - accuracy: 0.9657 - val_loss: 11.5174 - val_accuracy: 0.0767\n",
      "Epoch 416/500\n",
      "700/700 - 1s - loss: 0.0465 - accuracy: 0.9643 - val_loss: 11.5261 - val_accuracy: 0.0733\n",
      "Epoch 417/500\n",
      "700/700 - 1s - loss: 0.0477 - accuracy: 0.9643 - val_loss: 11.5311 - val_accuracy: 0.0767\n",
      "Epoch 418/500\n",
      "700/700 - 1s - loss: 0.0469 - accuracy: 0.9686 - val_loss: 11.5332 - val_accuracy: 0.0767\n",
      "Epoch 419/500\n",
      "700/700 - 0s - loss: 0.0460 - accuracy: 0.9657 - val_loss: 11.5401 - val_accuracy: 0.0733\n",
      "Epoch 420/500\n",
      "700/700 - 1s - loss: 0.0459 - accuracy: 0.9657 - val_loss: 11.5461 - val_accuracy: 0.0733\n",
      "Epoch 421/500\n",
      "700/700 - 1s - loss: 0.0459 - accuracy: 0.9671 - val_loss: 11.5526 - val_accuracy: 0.0733\n",
      "Epoch 422/500\n",
      "700/700 - 0s - loss: 0.0462 - accuracy: 0.9671 - val_loss: 11.5506 - val_accuracy: 0.0733\n",
      "Epoch 423/500\n",
      "700/700 - 0s - loss: 0.0464 - accuracy: 0.9700 - val_loss: 11.5570 - val_accuracy: 0.0733\n",
      "Epoch 424/500\n",
      "700/700 - 1s - loss: 0.0466 - accuracy: 0.9671 - val_loss: 11.5770 - val_accuracy: 0.0733\n",
      "Epoch 425/500\n",
      "700/700 - 1s - loss: 0.0459 - accuracy: 0.9657 - val_loss: 11.5748 - val_accuracy: 0.0733\n",
      "Epoch 426/500\n",
      "700/700 - 1s - loss: 0.0459 - accuracy: 0.9657 - val_loss: 11.5811 - val_accuracy: 0.0733\n",
      "Epoch 427/500\n",
      "700/700 - 1s - loss: 0.0468 - accuracy: 0.9686 - val_loss: 11.5834 - val_accuracy: 0.0767\n",
      "Epoch 428/500\n",
      "700/700 - 1s - loss: 0.0463 - accuracy: 0.9643 - val_loss: 11.5867 - val_accuracy: 0.0767\n",
      "Epoch 429/500\n",
      "700/700 - 1s - loss: 0.0463 - accuracy: 0.9643 - val_loss: 11.5896 - val_accuracy: 0.0733\n",
      "Epoch 430/500\n",
      "700/700 - 1s - loss: 0.0459 - accuracy: 0.9671 - val_loss: 11.6005 - val_accuracy: 0.0733\n",
      "Epoch 431/500\n",
      "700/700 - 1s - loss: 0.0465 - accuracy: 0.9643 - val_loss: 11.6024 - val_accuracy: 0.0767\n",
      "Epoch 432/500\n",
      "700/700 - 1s - loss: 0.0468 - accuracy: 0.9643 - val_loss: 11.6120 - val_accuracy: 0.0733\n",
      "Epoch 433/500\n",
      "700/700 - 1s - loss: 0.0461 - accuracy: 0.9671 - val_loss: 11.6209 - val_accuracy: 0.0733\n",
      "Epoch 434/500\n",
      "700/700 - 1s - loss: 0.0464 - accuracy: 0.9671 - val_loss: 11.6233 - val_accuracy: 0.0767\n",
      "Epoch 435/500\n",
      "700/700 - 1s - loss: 0.0472 - accuracy: 0.9714 - val_loss: 11.6283 - val_accuracy: 0.0733\n",
      "Epoch 436/500\n",
      "700/700 - 1s - loss: 0.0467 - accuracy: 0.9643 - val_loss: 11.6237 - val_accuracy: 0.0733\n",
      "Epoch 437/500\n",
      "700/700 - 1s - loss: 0.0466 - accuracy: 0.9643 - val_loss: 11.6392 - val_accuracy: 0.0733\n",
      "Epoch 438/500\n",
      "700/700 - 1s - loss: 0.0461 - accuracy: 0.9629 - val_loss: 11.6402 - val_accuracy: 0.0733\n",
      "Epoch 439/500\n",
      "700/700 - 1s - loss: 0.0462 - accuracy: 0.9671 - val_loss: 11.6528 - val_accuracy: 0.0733\n",
      "Epoch 440/500\n",
      "700/700 - 1s - loss: 0.0461 - accuracy: 0.9729 - val_loss: 11.6546 - val_accuracy: 0.0733\n",
      "Epoch 441/500\n",
      "700/700 - 1s - loss: 0.0460 - accuracy: 0.9643 - val_loss: 11.6630 - val_accuracy: 0.0733\n",
      "Epoch 442/500\n",
      "700/700 - 0s - loss: 0.0467 - accuracy: 0.9686 - val_loss: 11.6735 - val_accuracy: 0.0767\n",
      "Epoch 443/500\n",
      "700/700 - 1s - loss: 0.0453 - accuracy: 0.9700 - val_loss: 11.6722 - val_accuracy: 0.0733\n",
      "Epoch 444/500\n",
      "700/700 - 1s - loss: 0.0462 - accuracy: 0.9629 - val_loss: 11.6827 - val_accuracy: 0.0733\n",
      "Epoch 445/500\n",
      "700/700 - 1s - loss: 0.0469 - accuracy: 0.9629 - val_loss: 11.6831 - val_accuracy: 0.0733\n",
      "Epoch 446/500\n",
      "700/700 - 1s - loss: 0.0458 - accuracy: 0.9686 - val_loss: 11.6958 - val_accuracy: 0.0733\n",
      "Epoch 447/500\n",
      "700/700 - 1s - loss: 0.0463 - accuracy: 0.9629 - val_loss: 11.6887 - val_accuracy: 0.0767\n",
      "Epoch 448/500\n",
      "700/700 - 1s - loss: 0.0447 - accuracy: 0.9657 - val_loss: 11.6916 - val_accuracy: 0.0733\n",
      "Epoch 449/500\n",
      "700/700 - 1s - loss: 0.0474 - accuracy: 0.9614 - val_loss: 11.7078 - val_accuracy: 0.0733\n",
      "Epoch 450/500\n",
      "700/700 - 1s - loss: 0.0457 - accuracy: 0.9671 - val_loss: 11.7162 - val_accuracy: 0.0733\n",
      "Epoch 451/500\n",
      "700/700 - 1s - loss: 0.0465 - accuracy: 0.9614 - val_loss: 11.7107 - val_accuracy: 0.0767\n",
      "Epoch 452/500\n",
      "700/700 - 1s - loss: 0.0466 - accuracy: 0.9643 - val_loss: 11.7176 - val_accuracy: 0.0767\n",
      "Epoch 453/500\n",
      "700/700 - 1s - loss: 0.0463 - accuracy: 0.9671 - val_loss: 11.7220 - val_accuracy: 0.0733\n",
      "Epoch 454/500\n",
      "700/700 - 1s - loss: 0.0452 - accuracy: 0.9700 - val_loss: 11.7371 - val_accuracy: 0.0733\n",
      "Epoch 455/500\n",
      "700/700 - 0s - loss: 0.0458 - accuracy: 0.9657 - val_loss: 11.7414 - val_accuracy: 0.0767\n",
      "Epoch 456/500\n",
      "700/700 - 0s - loss: 0.0460 - accuracy: 0.9671 - val_loss: 11.7412 - val_accuracy: 0.0767\n",
      "Epoch 457/500\n",
      "700/700 - 1s - loss: 0.0468 - accuracy: 0.9643 - val_loss: 11.7363 - val_accuracy: 0.0767\n",
      "Epoch 458/500\n",
      "700/700 - 1s - loss: 0.0469 - accuracy: 0.9629 - val_loss: 11.7558 - val_accuracy: 0.0733\n",
      "Epoch 459/500\n",
      "700/700 - 1s - loss: 0.0461 - accuracy: 0.9643 - val_loss: 11.7572 - val_accuracy: 0.0733\n",
      "Epoch 460/500\n",
      "700/700 - 1s - loss: 0.0461 - accuracy: 0.9714 - val_loss: 11.7557 - val_accuracy: 0.0767\n",
      "Epoch 461/500\n",
      "700/700 - 1s - loss: 0.0460 - accuracy: 0.9643 - val_loss: 11.7658 - val_accuracy: 0.0733\n",
      "Epoch 462/500\n",
      "700/700 - 1s - loss: 0.0465 - accuracy: 0.9643 - val_loss: 11.7812 - val_accuracy: 0.0733\n",
      "Epoch 463/500\n",
      "700/700 - 1s - loss: 0.0464 - accuracy: 0.9629 - val_loss: 11.7760 - val_accuracy: 0.0733\n",
      "Epoch 464/500\n",
      "700/700 - 1s - loss: 0.0471 - accuracy: 0.9643 - val_loss: 11.7755 - val_accuracy: 0.0733\n",
      "Epoch 465/500\n",
      "700/700 - 1s - loss: 0.0463 - accuracy: 0.9686 - val_loss: 11.7924 - val_accuracy: 0.0767\n",
      "Epoch 466/500\n",
      "700/700 - 1s - loss: 0.0469 - accuracy: 0.9671 - val_loss: 11.7871 - val_accuracy: 0.0733\n",
      "Epoch 467/500\n",
      "700/700 - 1s - loss: 0.0460 - accuracy: 0.9657 - val_loss: 11.7959 - val_accuracy: 0.0733\n",
      "Epoch 468/500\n",
      "700/700 - 1s - loss: 0.0464 - accuracy: 0.9643 - val_loss: 11.8072 - val_accuracy: 0.0733\n",
      "Epoch 469/500\n",
      "700/700 - 1s - loss: 0.0452 - accuracy: 0.9686 - val_loss: 11.8148 - val_accuracy: 0.0733\n",
      "Epoch 470/500\n",
      "700/700 - 1s - loss: 0.0458 - accuracy: 0.9657 - val_loss: 11.8153 - val_accuracy: 0.0733\n",
      "Epoch 471/500\n",
      "700/700 - 1s - loss: 0.0455 - accuracy: 0.9671 - val_loss: 11.8231 - val_accuracy: 0.0733\n",
      "Epoch 472/500\n",
      "700/700 - 1s - loss: 0.0462 - accuracy: 0.9643 - val_loss: 11.8275 - val_accuracy: 0.0733\n",
      "Epoch 473/500\n",
      "700/700 - 1s - loss: 0.0455 - accuracy: 0.9714 - val_loss: 11.8336 - val_accuracy: 0.0733\n",
      "Epoch 474/500\n",
      "700/700 - 1s - loss: 0.0453 - accuracy: 0.9643 - val_loss: 11.8280 - val_accuracy: 0.0767\n",
      "Epoch 475/500\n",
      "700/700 - 1s - loss: 0.0454 - accuracy: 0.9671 - val_loss: 11.8368 - val_accuracy: 0.0733\n",
      "Epoch 476/500\n",
      "700/700 - 1s - loss: 0.0453 - accuracy: 0.9643 - val_loss: 11.8456 - val_accuracy: 0.0733\n",
      "Epoch 477/500\n",
      "700/700 - 1s - loss: 0.0465 - accuracy: 0.9686 - val_loss: 11.8387 - val_accuracy: 0.0733\n",
      "Epoch 478/500\n",
      "700/700 - 1s - loss: 0.0457 - accuracy: 0.9671 - val_loss: 11.8522 - val_accuracy: 0.0733\n",
      "Epoch 479/500\n",
      "700/700 - 1s - loss: 0.0464 - accuracy: 0.9657 - val_loss: 11.8596 - val_accuracy: 0.0733\n",
      "Epoch 480/500\n",
      "700/700 - 1s - loss: 0.0454 - accuracy: 0.9671 - val_loss: 11.8516 - val_accuracy: 0.0733\n",
      "Epoch 481/500\n",
      "700/700 - 1s - loss: 0.0454 - accuracy: 0.9643 - val_loss: 11.8669 - val_accuracy: 0.0767\n",
      "Epoch 482/500\n",
      "700/700 - 1s - loss: 0.0465 - accuracy: 0.9686 - val_loss: 11.8658 - val_accuracy: 0.0733\n",
      "Epoch 483/500\n",
      "700/700 - 1s - loss: 0.0462 - accuracy: 0.9643 - val_loss: 11.8655 - val_accuracy: 0.0733\n",
      "Epoch 484/500\n",
      "700/700 - 1s - loss: 0.0466 - accuracy: 0.9657 - val_loss: 11.8711 - val_accuracy: 0.0733\n",
      "Epoch 485/500\n",
      "700/700 - 1s - loss: 0.0449 - accuracy: 0.9700 - val_loss: 11.8777 - val_accuracy: 0.0733\n",
      "Epoch 486/500\n",
      "700/700 - 0s - loss: 0.0455 - accuracy: 0.9643 - val_loss: 11.8853 - val_accuracy: 0.0700\n",
      "Epoch 487/500\n",
      "700/700 - 1s - loss: 0.0448 - accuracy: 0.9671 - val_loss: 11.8915 - val_accuracy: 0.0733\n",
      "Epoch 488/500\n",
      "700/700 - 1s - loss: 0.0455 - accuracy: 0.9671 - val_loss: 11.9005 - val_accuracy: 0.0700\n",
      "Epoch 489/500\n",
      "700/700 - 1s - loss: 0.0460 - accuracy: 0.9614 - val_loss: 11.8899 - val_accuracy: 0.0733\n",
      "Epoch 490/500\n",
      "700/700 - 1s - loss: 0.0457 - accuracy: 0.9671 - val_loss: 11.9115 - val_accuracy: 0.0733\n",
      "Epoch 491/500\n",
      "700/700 - 1s - loss: 0.0461 - accuracy: 0.9700 - val_loss: 11.9092 - val_accuracy: 0.0733\n",
      "Epoch 492/500\n",
      "700/700 - 1s - loss: 0.0454 - accuracy: 0.9657 - val_loss: 11.9147 - val_accuracy: 0.0700\n",
      "Epoch 493/500\n",
      "700/700 - 1s - loss: 0.0457 - accuracy: 0.9614 - val_loss: 11.9211 - val_accuracy: 0.0700\n",
      "Epoch 494/500\n",
      "700/700 - 1s - loss: 0.0462 - accuracy: 0.9614 - val_loss: 11.9189 - val_accuracy: 0.0700\n",
      "Epoch 495/500\n",
      "700/700 - 1s - loss: 0.0452 - accuracy: 0.9657 - val_loss: 11.9258 - val_accuracy: 0.0700\n",
      "Epoch 496/500\n",
      "700/700 - 1s - loss: 0.0460 - accuracy: 0.9671 - val_loss: 11.9362 - val_accuracy: 0.0700\n",
      "Epoch 497/500\n",
      "700/700 - 1s - loss: 0.0449 - accuracy: 0.9686 - val_loss: 11.9347 - val_accuracy: 0.0700\n",
      "Epoch 498/500\n",
      "700/700 - 1s - loss: 0.0451 - accuracy: 0.9657 - val_loss: 11.9399 - val_accuracy: 0.0700\n",
      "Epoch 499/500\n",
      "700/700 - 1s - loss: 0.0452 - accuracy: 0.9657 - val_loss: 11.9384 - val_accuracy: 0.0700\n",
      "Epoch 500/500\n",
      "700/700 - 1s - loss: 0.0460 - accuracy: 0.9671 - val_loss: 11.9449 - val_accuracy: 0.0700\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,epochs=500,verbose=2,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLotting loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Epochs')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Epochs')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Generate a Poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem(input,length):\n",
    "    seed_text=input\n",
    "    output=''\n",
    "    for i in range(length):\n",
    "        token_list=tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list=pad_sequences([token_list],maxlen=8,padding='pre')   # truncating from the beginning\n",
    "        class1=model.predict_classes(token_list.reshape(1,8))\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if(class1==index):\n",
    "                break\n",
    "        seed_text=seed_text+\" \"+word\n",
    "    return(print(seed_text))               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a midnight dreary, while i implore i broken sculptured stillness bore thing of evil – prophet for forget forget melancholy and muttered other burden\n"
     ]
    }
   ],
   "source": [
    "generate_poem(\"Once upon a midnight dreary, while\",20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
